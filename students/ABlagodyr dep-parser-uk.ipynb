{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition-based arc-eager unlabeled dependency parser for Ukrainian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "Useful links:\n",
    "* [UD corpus for Ukrainian](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
    "* [Easy-to-use library for parsing UD](https://github.com/EmilStenstrom/conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"UD_Ukrainian-IU\"\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-train.conllu\", \"r\", encoding='utf-8') as f:\n",
    "    dev_trees = parse(f.read())\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-train.conllu\", \"r\", encoding='utf-8') as f:\n",
    "    train_trees = parse(f.read())\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-dev.conllu\", \"r\", encoding='utf-8') as f:\n",
    "    test_trees = parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5496\n",
      "5496\n",
      "672\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_trees))\n",
    "print(len(train_trees))\n",
    "print(len(test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenList<У, домі, римського, патриція, Руфіна, була, прегарна, фреска, ,, зображення, Венери, та, Адоніса, .>\n",
      "{'id': 1, 'form': 'У', 'lemma': 'у', 'upos': 'ADP', 'xpos': 'Spsl', 'feats': {'Case': 'Loc'}, 'head': 2, 'deprel': 'case', 'deps': [('case', 2)], 'misc': {'Id': '0003', 'LTranslit': 'u', 'Translit': 'U'}}\n",
      "{'id': 2, 'form': 'домі', 'lemma': 'дім', 'upos': 'NOUN', 'xpos': 'Ncmsln', 'feats': {'Animacy': 'Inan', 'Case': 'Loc', 'Gender': 'Masc', 'Number': 'Sing'}, 'head': 6, 'deprel': 'obl', 'deps': [('obl', 6)], 'misc': {'Id': '0004', 'LTranslit': 'dim', 'Translit': 'domi'}}\n",
      "{'id': 3, 'form': 'римського', 'lemma': 'римський', 'upos': 'ADJ', 'xpos': 'Ao-msgf', 'feats': {'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}, 'head': 4, 'deprel': 'amod', 'deps': [('amod', 4)], 'misc': {'Id': '0005', 'LTranslit': 'rymśkyj', 'Translit': 'rymśkoho'}}\n",
      "{'id': 4, 'form': 'патриція', 'lemma': 'патрицій', 'upos': 'NOUN', 'xpos': 'Ncmsgy', 'feats': {'Animacy': 'Anim', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}, 'head': 2, 'deprel': 'nmod', 'deps': [('nmod', 2)], 'misc': {'Id': '0006', 'LTranslit': 'patrycij', 'Translit': 'patrycija'}}\n",
      "{'id': 5, 'form': 'Руфіна', 'lemma': 'Руфін', 'upos': 'PROPN', 'xpos': 'Npmsgy', 'feats': {'Animacy': 'Anim', 'Case': 'Gen', 'Gender': 'Masc', 'NameType': 'Giv', 'Number': 'Sing'}, 'head': 4, 'deprel': 'flat:title', 'deps': [('flat:title', 4)], 'misc': {'Id': '0007', 'LTranslit': 'Rufin', 'Translit': 'Rufina'}}\n",
      "{'id': 6, 'form': 'була', 'lemma': 'бути', 'upos': 'VERB', 'xpos': 'Vapis-sf', 'feats': {'Aspect': 'Imp', 'Gender': 'Fem', 'Mood': 'Ind', 'Number': 'Sing', 'Tense': 'Past', 'VerbForm': 'Fin'}, 'head': 0, 'deprel': 'root', 'deps': [('root', 0)], 'misc': {'Id': '0008', 'LTranslit': 'buty', 'Translit': 'bula'}}\n",
      "{'id': 7, 'form': 'прегарна', 'lemma': 'прегарний', 'upos': 'ADJ', 'xpos': 'Ao-fsns', 'feats': {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing'}, 'head': 8, 'deprel': 'amod', 'deps': [('amod', 8)], 'misc': {'Id': '0009', 'LTranslit': 'preharnyj', 'Translit': 'preharna'}}\n",
      "{'id': 8, 'form': 'фреска', 'lemma': 'фреска', 'upos': 'NOUN', 'xpos': 'Ncfsnn', 'feats': {'Animacy': 'Inan', 'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing'}, 'head': 6, 'deprel': 'nsubj', 'deps': [('nsubj', 6)], 'misc': {'Id': '000a', 'LTranslit': 'freska', 'SpaceAfter': 'No', 'Translit': 'freska'}}\n",
      "{'id': 9, 'form': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': 'U', 'feats': None, 'head': 10, 'deprel': 'punct', 'deps': [('punct', 10)], 'misc': {'Id': '000b', 'LTranslit': ',', 'Translit': ','}}\n",
      "{'id': 10, 'form': 'зображення', 'lemma': 'зображення', 'upos': 'NOUN', 'xpos': 'Ncnsnn', 'feats': {'Animacy': 'Inan', 'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing'}, 'head': 8, 'deprel': 'appos', 'deps': [('appos', 8)], 'misc': {'Id': '000c', 'LTranslit': 'zobraženńа', 'Translit': 'zobraženńа'}}\n",
      "{'id': 11, 'form': 'Венери', 'lemma': 'Венера', 'upos': 'PROPN', 'xpos': 'Npfsgy', 'feats': {'Animacy': 'Anim', 'Case': 'Gen', 'Gender': 'Fem', 'NameType': 'Giv', 'Number': 'Sing'}, 'head': 10, 'deprel': 'nmod', 'deps': [('nmod', 10)], 'misc': {'Id': '000d', 'LTranslit': 'Venera', 'Translit': 'Venery'}}\n",
      "{'id': 12, 'form': 'та', 'lemma': 'та', 'upos': 'CCONJ', 'xpos': 'Ccs', 'feats': None, 'head': 13, 'deprel': 'cc', 'deps': [('cc', 13)], 'misc': {'Id': '000e', 'LTranslit': 'ta', 'Translit': 'ta'}}\n",
      "{'id': 13, 'form': 'Адоніса', 'lemma': 'Адоніс', 'upos': 'PROPN', 'xpos': 'Npmsgy', 'feats': {'Animacy': 'Anim', 'Case': 'Gen', 'Gender': 'Masc', 'NameType': 'Giv', 'Number': 'Sing'}, 'head': 11, 'deprel': 'conj', 'deps': [('nmod', 10), ('conj', 11)], 'misc': {'Id': '000f', 'LTranslit': 'Adonis', 'SpaceAfter': 'No', 'Translit': 'Adonisa'}}\n",
      "{'id': 14, 'form': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': 'U', 'feats': None, 'head': 6, 'deprel': 'punct', 'deps': [('punct', 6)], 'misc': {'Id': '000g', 'LTranslit': '.', 'Translit': '.'}}\n"
     ]
    }
   ],
   "source": [
    "tree=dev_trees[0]\n",
    "print(tree)\n",
    "for node in tree:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design actions and the oracle\n",
    "\n",
    "We will be using a static oracle that reproduces a single valid order of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack: ['ROOT_0']\n",
      "Queue: ['У_1', 'домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: []\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'У_1']\n",
      "Queue: ['домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: []\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: ['домі_2', 'римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['римського_3', 'патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'римського_3']\n",
      "Queue: ['патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['патриція_4', 'Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4']\n",
      "Queue: ['Руфіна_5', 'була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4', 'Руфіна_5']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2', 'патриція_4']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'домі_2']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: ['була_6', 'прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['прегарна_7', 'фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'прегарна_7']\n",
      "Queue: ['фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['фреска_8', ',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: [',_9', 'зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', ',_9']\n",
      "Queue: ['зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: ['зображення_10', 'Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10']\n",
      "Queue: ['Венери_11', 'та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['та_12', 'Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11', 'та_12']\n",
      "Queue: ['Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['Адоніса_13', '._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11', 'Адоніса_13']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10', 'Венери_11']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8', 'зображення_10']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', 'фреска_8']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: ['._14']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6', '._14']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0', 'була_6']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT_0']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Gold relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Retrieved relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n"
     ]
    }
   ],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))\n",
    "\n",
    "trace_actions(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature extraction\n",
    "\n",
    "Reference: [Dependency Parsing by Kübler, McDonald, and Nivre](https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA21&hl=uk&source=gbs_toc_r&cad=4#v=onepage&q&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 111126\n",
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The first iteration is increasing the number of  additional features from 111126 to 617023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 617023\n",
    "def extract_features_extended(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        for i in range(len(stack)):\n",
    "            stack_top = stack[-i-1]\n",
    "            features[\"s0{}-word\".format(i)] = stack_top[\"form\"]\n",
    "            features[\"s0{}-lemma\".format(i)] = stack_top[\"lemma\"]\n",
    "            features[\"s0{}-tag\".format(i)] = stack_top[\"upostag\"]\n",
    "            if stack_top[\"feats\"]:\n",
    "                for key, val in stack_top[\"feats\"].items():\n",
    "                    features[\"s0{}-\".format(i) + key] = val\n",
    "            if stack_top[\"misc\"]:\n",
    "                for key, val in stack_top[\"misc\"].items():\n",
    "                    features[\"s0{}-\".format(i) + key] = val\n",
    "    if len(stack) > 1:\n",
    "        for i in range(1, len(stack)):\n",
    "            features[\"s0{}-tag\".format(i)] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        if queue[0][\"feats\"]:\n",
    "            for key, val in queue[0][\"feats\"].items():\n",
    "                features[\"q0-\" + key] = val\n",
    "        if stack_top[\"misc\"]:\n",
    "            for key, val in stack_top[\"misc\"].items():\n",
    "                features[\"s0{}-\".format(i) + key] = val\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-lemma\"] = queue_next[\"lemma\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features_extended(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190298 190298\n"
     ]
    }
   ],
   "source": [
    "# A simple hack would be to check the type of the node id\n",
    "\n",
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25820 25820\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# https://analyticsindiamag.com/a-beginners-guide-to-scikit-learns-mlpclassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "# print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\", max_iter=600, verbose=1)\n",
    "lrc.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Basic reults:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.86      0.87      0.86      6371\n",
    "#       reduce       0.85      0.78      0.81      6875\n",
    "#        right       0.75      0.79      0.77      5996\n",
    "#        shift       0.85      0.87      0.86      6578\n",
    "\n",
    "#     accuracy                           0.83     25820\n",
    "#    macro avg       0.83      0.83      0.83     25820\n",
    "# weighted avg       0.83      0.83      0.83     25820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### The best model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Result with extended list of features:\n",
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iteration 2:\n",
    "# Using Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=12, verbose=True,\n",
    "                    learning_rate_init=0.1, max_iter=600)\n",
    "\n",
    "mlp.fit(train_features_vectorized, train_labels)\n",
    "predicted = mlp.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.66      0.95      0.78      6371\n",
    "#       reduce       0.89      0.60      0.71      6875\n",
    "#        right       0.75      0.76      0.76      5996\n",
    "#        shift       0.90      0.81      0.85      6578\n",
    "\n",
    "#     accuracy                           0.78     25820\n",
    "#    macro avg       0.80      0.78      0.78     25820\n",
    "# weighted avg       0.80      0.78      0.77     25820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iteration 3:\n",
    "# Using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnnb = MultinomialNB()\n",
    "mnnb.fit(train_features_vectorized, train_labels)\n",
    "predicted_mnnb = mnnb.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted_mnnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.70      0.82      0.76      6371\n",
    "#       reduce       0.72      0.55      0.62      6875\n",
    "#        right       0.53      0.69      0.60      5996\n",
    "#        shift       0.83      0.66      0.74      6578\n",
    "\n",
    "#     accuracy                           0.68     25820\n",
    "#    macro avg       0.70      0.68      0.68     25820\n",
    "# weighted avg       0.70      0.68      0.68     25820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Calculate the unlabeled attachment score\n",
    "UAS - the percentage of words in an input that are assigned the correct head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features_extended(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  616765\n"
     ]
    }
   ],
   "source": [
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "# print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 298 epochs took 191 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=600, multi_class='multinomial', random_state=42,\n",
       "                   solver='saga', verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\", max_iter=600, verbose=1)\n",
    "lrc.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic reults:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.86      0.87      0.86      6371\n",
    "#       reduce       0.85      0.78      0.81      6875\n",
    "#        right       0.75      0.79      0.77      5996\n",
    "#        shift       0.85      0.87      0.86      6578\n",
    "\n",
    "#     accuracy                           0.83     25820\n",
    "#    macro avg       0.83      0.83      0.83     25820\n",
    "# weighted avg       0.83      0.83      0.83     25820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.87      0.89      0.88      6371\n",
      "      reduce       0.86      0.81      0.83      6875\n",
      "       right       0.77      0.80      0.79      5996\n",
      "       shift       0.85      0.86      0.86      6578\n",
      "\n",
      "    accuracy                           0.84     25820\n",
      "   macro avg       0.84      0.84      0.84     25820\n",
      "weighted avg       0.84      0.84      0.84     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Result with extended list of features:\n",
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 2:\n",
    "# Using Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.85093716\n",
      "Iteration 2, loss = 0.77250871\n",
      "Iteration 3, loss = 0.77026892\n",
      "Iteration 4, loss = 0.77419655\n",
      "Iteration 5, loss = 0.77052740\n",
      "Iteration 6, loss = 0.77731507\n",
      "Iteration 7, loss = 0.78225686\n",
      "Iteration 8, loss = 0.77162010\n",
      "Iteration 9, loss = 0.78228451\n",
      "Iteration 10, loss = 0.78471614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ucuniversity\\nlp\\module2\\rulebased\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.66      0.95      0.78      6371\n",
      "      reduce       0.89      0.60      0.71      6875\n",
      "       right       0.75      0.76      0.76      5996\n",
      "       shift       0.90      0.81      0.85      6578\n",
      "\n",
      "    accuracy                           0.78     25820\n",
      "   macro avg       0.80      0.78      0.78     25820\n",
      "weighted avg       0.80      0.78      0.77     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=12, verbose=True,\n",
    "                    learning_rate_init=0.1, max_iter=600)\n",
    "\n",
    "mlp.fit(train_features_vectorized, train_labels)\n",
    "predicted = mlp.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.66      0.95      0.78      6371\n",
    "#       reduce       0.89      0.60      0.71      6875\n",
    "#        right       0.75      0.76      0.76      5996\n",
    "#        shift       0.90      0.81      0.85      6578\n",
    "\n",
    "#     accuracy                           0.78     25820\n",
    "#    macro avg       0.80      0.78      0.78     25820\n",
    "# weighted avg       0.80      0.78      0.77     25820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 3:\n",
    "# Using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.70      0.82      0.76      6371\n",
      "      reduce       0.72      0.55      0.62      6875\n",
      "       right       0.53      0.69      0.60      5996\n",
      "       shift       0.83      0.66      0.74      6578\n",
      "\n",
      "    accuracy                           0.68     25820\n",
      "   macro avg       0.70      0.68      0.68     25820\n",
      "weighted avg       0.70      0.68      0.68     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnnb = MultinomialNB()\n",
    "mnnb.fit(train_features_vectorized, train_labels)\n",
    "predicted_mnnb = mnnb.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted_mnnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         left       0.70      0.82      0.76      6371\n",
    "#       reduce       0.72      0.55      0.62      6875\n",
    "#        right       0.53      0.69      0.60      5996\n",
    "#        shift       0.83      0.66      0.74      6578\n",
    "\n",
    "#     accuracy                           0.68     25820\n",
    "#    macro avg       0.70      0.68      0.68     25820\n",
    "# weighted avg       0.70      0.68      0.68     25820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the unlabeled attachment score\n",
    "UAS - the percentage of words in an input that are assigned the correct head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features_extended(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correctly defined: 8857\n",
      "UAS: 0.7\n",
      "Full match: 0.11\n"
     ]
    }
   ],
   "source": [
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find non-projective trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of non-projective trees is 7.99 (439 out of 5496).\n",
      "IDs: [4, 9, 13, 19, 22, 28, 29, 33, 34, 43]\n"
     ]
    }
   ],
   "source": [
    "def is_non_projective(tree):\n",
    "    relations = [[i['id'], i['head']] for i in tree if type(i[\"id\"])==int]\n",
    "    for rel in relations:\n",
    "        for ref_rel in relations:\n",
    "            a, c = sorted(rel)\n",
    "            b, d = sorted(ref_rel)\n",
    "            if a < b and b < c and c < d:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "total_non_pr = 0\n",
    "tree_ids = []\n",
    "for i in range(len(train_trees)):\n",
    "    if is_non_projective(train_trees[i]):\n",
    "        total_non_pr += 1\n",
    "        tree_ids.append(i)\n",
    "\n",
    "print(\"The percentage of non-projective trees is {} ({} out of {}).\".\n",
    "      format(round(total_non_pr * 100 / len(train_trees), 2), total_non_pr, len(train_trees)))\n",
    "\n",
    "print(\"IDs:\", tree_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
